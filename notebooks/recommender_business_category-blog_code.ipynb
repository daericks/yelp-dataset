{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Recommender-system-for-business-categories-of-Yelp-businesses.-Uses-reviews\" data-toc-modified-id=\"Recommender-system-for-business-categories-of-Yelp-businesses.-Uses-reviews-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Recommender system for business categories of Yelp businesses. Uses reviews</a></span></li><li><span><a href=\"#ETL-(Extract,-Transform,-Load)\" data-toc-modified-id=\"ETL-(Extract,-Transform,-Load)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ETL (Extract, Transform, Load)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Review-data\" data-toc-modified-id=\"Review-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Review data</a></span></li><li><span><a href=\"#Merge-with-Business-Categories\" data-toc-modified-id=\"Merge-with-Business-Categories-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Merge with Business Categories</a></span></li></ul></li><li><span><a href=\"#Train-the-Recommender\" data-toc-modified-id=\"Train-the-Recommender-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train the Recommender</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:27:47.959842Z",
     "start_time": "2020-01-23T04:27:47.954128Z"
    }
   },
   "source": [
    "# Recommender system for business categories of Yelp businesses. Uses reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:06:01.404690Z",
     "start_time": "2020-01-23T05:05:55.652490Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daviderickson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:29:11.535609Z",
     "start_time": "2020-01-23T04:29:11.532284Z"
    }
   },
   "source": [
    "# ETL (Extract, Transform, Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:32:53.965254Z",
     "start_time": "2020-01-23T04:32:53.958871Z"
    }
   },
   "source": [
    "## Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:06:02.538595Z",
     "start_time": "2020-01-23T05:06:01.410563Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_reviews(size='small'): \n",
    "    if size == 'small':\n",
    "        filename = r'../../data/small-review.json'\n",
    "    elif size == 'intermediate':\n",
    "        filename = r'../../data/intermediate-review.json'\n",
    "    elif size == 'full':\n",
    "        filename = r'../../data/review.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfreviews = load_reviews(size='intermediate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:06:02.549601Z",
     "start_time": "2020-01-23T05:06:02.541567Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(string, remove_stopwords=False):\n",
    "    string = re.sub(\"[^a-zA-Z]\", \" \", string) # keep only letters. more complex model possible later\n",
    "    words =  string.lower().split() # make everything lowercase. split into words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english')) # create a fast lookup for stopwords\n",
    "        words = [w for w in words if not w in stops] # remove stopwords\n",
    "    return( words) # return a list of words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:06:02.569672Z",
     "start_time": "2020-01-23T05:06:02.553717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec expects single sentences, each one as a list of words\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:06:29.726232Z",
     "start_time": "2020-01-23T05:06:02.576147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences\")\n",
    "for review in dfreviews[\"text\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:07:17.255651Z",
     "start_time": "2020-01-23T05:06:29.728658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:06:30,549 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2020-01-22 21:06:30,557 : INFO : collecting all words and their counts\n",
      "2020-01-22 21:06:30,558 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-01-22 21:06:30,600 : INFO : PROGRESS: at sentence #10000, processed 140966 words, keeping 9537 word types\n",
      "2020-01-22 21:06:30,642 : INFO : PROGRESS: at sentence #20000, processed 279509 words, keeping 13297 word types\n",
      "2020-01-22 21:06:30,674 : INFO : PROGRESS: at sentence #30000, processed 416170 words, keeping 16108 word types\n",
      "2020-01-22 21:06:30,703 : INFO : PROGRESS: at sentence #40000, processed 552466 words, keeping 18464 word types\n",
      "2020-01-22 21:06:30,753 : INFO : PROGRESS: at sentence #50000, processed 690423 words, keeping 20660 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:06:30,787 : INFO : PROGRESS: at sentence #60000, processed 829572 words, keeping 22414 word types\n",
      "2020-01-22 21:06:30,840 : INFO : PROGRESS: at sentence #70000, processed 967451 words, keeping 24105 word types\n",
      "2020-01-22 21:06:30,868 : INFO : PROGRESS: at sentence #80000, processed 1106355 words, keeping 25709 word types\n",
      "2020-01-22 21:06:30,905 : INFO : PROGRESS: at sentence #90000, processed 1245199 words, keeping 27118 word types\n",
      "2020-01-22 21:06:30,936 : INFO : PROGRESS: at sentence #100000, processed 1385155 words, keeping 28435 word types\n",
      "2020-01-22 21:06:30,971 : INFO : PROGRESS: at sentence #110000, processed 1522186 words, keeping 29854 word types\n",
      "2020-01-22 21:06:31,011 : INFO : PROGRESS: at sentence #120000, processed 1658125 words, keeping 31115 word types\n",
      "2020-01-22 21:06:31,039 : INFO : PROGRESS: at sentence #130000, processed 1797345 words, keeping 32404 word types\n",
      "2020-01-22 21:06:31,078 : INFO : PROGRESS: at sentence #140000, processed 1935475 words, keeping 33568 word types\n",
      "2020-01-22 21:06:31,105 : INFO : PROGRESS: at sentence #150000, processed 2074816 words, keeping 34612 word types\n",
      "2020-01-22 21:06:31,135 : INFO : PROGRESS: at sentence #160000, processed 2211922 words, keeping 35735 word types\n",
      "2020-01-22 21:06:31,166 : INFO : PROGRESS: at sentence #170000, processed 2347735 words, keeping 36668 word types\n",
      "2020-01-22 21:06:31,197 : INFO : PROGRESS: at sentence #180000, processed 2488067 words, keeping 37576 word types\n",
      "2020-01-22 21:06:31,228 : INFO : PROGRESS: at sentence #190000, processed 2625228 words, keeping 38448 word types\n",
      "2020-01-22 21:06:31,259 : INFO : PROGRESS: at sentence #200000, processed 2760045 words, keeping 39490 word types\n",
      "2020-01-22 21:06:31,304 : INFO : PROGRESS: at sentence #210000, processed 2898041 words, keeping 40365 word types\n",
      "2020-01-22 21:06:31,333 : INFO : PROGRESS: at sentence #220000, processed 3034056 words, keeping 41262 word types\n",
      "2020-01-22 21:06:31,365 : INFO : PROGRESS: at sentence #230000, processed 3173822 words, keeping 42201 word types\n",
      "2020-01-22 21:06:31,400 : INFO : PROGRESS: at sentence #240000, processed 3313085 words, keeping 43150 word types\n",
      "2020-01-22 21:06:31,437 : INFO : PROGRESS: at sentence #250000, processed 3455109 words, keeping 43971 word types\n",
      "2020-01-22 21:06:31,485 : INFO : PROGRESS: at sentence #260000, processed 3594317 words, keeping 44784 word types\n",
      "2020-01-22 21:06:31,511 : INFO : PROGRESS: at sentence #270000, processed 3734590 words, keeping 45550 word types\n",
      "2020-01-22 21:06:31,541 : INFO : PROGRESS: at sentence #280000, processed 3870748 words, keeping 46312 word types\n",
      "2020-01-22 21:06:31,567 : INFO : PROGRESS: at sentence #290000, processed 4006164 words, keeping 47097 word types\n",
      "2020-01-22 21:06:31,597 : INFO : PROGRESS: at sentence #300000, processed 4143319 words, keeping 47781 word types\n",
      "2020-01-22 21:06:31,633 : INFO : PROGRESS: at sentence #310000, processed 4283740 words, keeping 48478 word types\n",
      "2020-01-22 21:06:31,662 : INFO : PROGRESS: at sentence #320000, processed 4422585 words, keeping 49105 word types\n",
      "2020-01-22 21:06:31,696 : INFO : PROGRESS: at sentence #330000, processed 4560689 words, keeping 49851 word types\n",
      "2020-01-22 21:06:31,723 : INFO : PROGRESS: at sentence #340000, processed 4699298 words, keeping 50451 word types\n",
      "2020-01-22 21:06:31,755 : INFO : PROGRESS: at sentence #350000, processed 4839144 words, keeping 51110 word types\n",
      "2020-01-22 21:06:31,786 : INFO : PROGRESS: at sentence #360000, processed 4977867 words, keeping 51749 word types\n",
      "2020-01-22 21:06:31,820 : INFO : PROGRESS: at sentence #370000, processed 5117768 words, keeping 52413 word types\n",
      "2020-01-22 21:06:31,852 : INFO : PROGRESS: at sentence #380000, processed 5253185 words, keeping 53011 word types\n",
      "2020-01-22 21:06:31,888 : INFO : PROGRESS: at sentence #390000, processed 5391056 words, keeping 53645 word types\n",
      "2020-01-22 21:06:31,913 : INFO : PROGRESS: at sentence #400000, processed 5526783 words, keeping 54160 word types\n",
      "2020-01-22 21:06:31,943 : INFO : PROGRESS: at sentence #410000, processed 5665316 words, keeping 54708 word types\n",
      "2020-01-22 21:06:31,977 : INFO : PROGRESS: at sentence #420000, processed 5802570 words, keeping 55265 word types\n",
      "2020-01-22 21:06:32,008 : INFO : PROGRESS: at sentence #430000, processed 5943274 words, keeping 55836 word types\n",
      "2020-01-22 21:06:32,036 : INFO : PROGRESS: at sentence #440000, processed 6082899 words, keeping 56453 word types\n",
      "2020-01-22 21:06:32,065 : INFO : PROGRESS: at sentence #450000, processed 6222326 words, keeping 57059 word types\n",
      "2020-01-22 21:06:32,098 : INFO : PROGRESS: at sentence #460000, processed 6361761 words, keeping 57570 word types\n",
      "2020-01-22 21:06:32,140 : INFO : PROGRESS: at sentence #470000, processed 6501789 words, keeping 58120 word types\n",
      "2020-01-22 21:06:32,166 : INFO : PROGRESS: at sentence #480000, processed 6641871 words, keeping 58597 word types\n",
      "2020-01-22 21:06:32,194 : INFO : PROGRESS: at sentence #490000, processed 6778331 words, keeping 59152 word types\n",
      "2020-01-22 21:06:32,226 : INFO : PROGRESS: at sentence #500000, processed 6917652 words, keeping 59660 word types\n",
      "2020-01-22 21:06:32,259 : INFO : PROGRESS: at sentence #510000, processed 7054305 words, keeping 60216 word types\n",
      "2020-01-22 21:06:32,286 : INFO : PROGRESS: at sentence #520000, processed 7192561 words, keeping 60946 word types\n",
      "2020-01-22 21:06:32,315 : INFO : PROGRESS: at sentence #530000, processed 7331639 words, keeping 61435 word types\n",
      "2020-01-22 21:06:32,349 : INFO : PROGRESS: at sentence #540000, processed 7466412 words, keeping 61967 word types\n",
      "2020-01-22 21:06:32,376 : INFO : PROGRESS: at sentence #550000, processed 7606024 words, keeping 62444 word types\n",
      "2020-01-22 21:06:32,406 : INFO : PROGRESS: at sentence #560000, processed 7743467 words, keeping 62975 word types\n",
      "2020-01-22 21:06:32,445 : INFO : PROGRESS: at sentence #570000, processed 7886000 words, keeping 63441 word types\n",
      "2020-01-22 21:06:32,471 : INFO : PROGRESS: at sentence #580000, processed 8024498 words, keeping 63903 word types\n",
      "2020-01-22 21:06:32,502 : INFO : PROGRESS: at sentence #590000, processed 8163620 words, keeping 64465 word types\n",
      "2020-01-22 21:06:32,536 : INFO : PROGRESS: at sentence #600000, processed 8301154 words, keeping 64958 word types\n",
      "2020-01-22 21:06:32,569 : INFO : PROGRESS: at sentence #610000, processed 8439914 words, keeping 65389 word types\n",
      "2020-01-22 21:06:32,600 : INFO : PROGRESS: at sentence #620000, processed 8576668 words, keeping 65856 word types\n",
      "2020-01-22 21:06:32,632 : INFO : PROGRESS: at sentence #630000, processed 8716026 words, keeping 66276 word types\n",
      "2020-01-22 21:06:32,664 : INFO : PROGRESS: at sentence #640000, processed 8854192 words, keeping 66797 word types\n",
      "2020-01-22 21:06:32,694 : INFO : PROGRESS: at sentence #650000, processed 8993077 words, keeping 67312 word types\n",
      "2020-01-22 21:06:32,727 : INFO : PROGRESS: at sentence #660000, processed 9129112 words, keeping 67809 word types\n",
      "2020-01-22 21:06:32,762 : INFO : PROGRESS: at sentence #670000, processed 9268587 words, keeping 68228 word types\n",
      "2020-01-22 21:06:32,791 : INFO : PROGRESS: at sentence #680000, processed 9406880 words, keeping 68668 word types\n",
      "2020-01-22 21:06:32,833 : INFO : PROGRESS: at sentence #690000, processed 9546298 words, keeping 69107 word types\n",
      "2020-01-22 21:06:32,862 : INFO : PROGRESS: at sentence #700000, processed 9685619 words, keeping 69538 word types\n",
      "2020-01-22 21:06:32,898 : INFO : PROGRESS: at sentence #710000, processed 9824418 words, keeping 70055 word types\n",
      "2020-01-22 21:06:32,930 : INFO : PROGRESS: at sentence #720000, processed 9962900 words, keeping 70456 word types\n",
      "2020-01-22 21:06:32,960 : INFO : PROGRESS: at sentence #730000, processed 10098717 words, keeping 70840 word types\n",
      "2020-01-22 21:06:32,994 : INFO : PROGRESS: at sentence #740000, processed 10237042 words, keeping 71317 word types\n",
      "2020-01-22 21:06:33,024 : INFO : PROGRESS: at sentence #750000, processed 10375581 words, keeping 71843 word types\n",
      "2020-01-22 21:06:33,060 : INFO : PROGRESS: at sentence #760000, processed 10515679 words, keeping 72299 word types\n",
      "2020-01-22 21:06:33,085 : INFO : PROGRESS: at sentence #770000, processed 10654391 words, keeping 72720 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:06:33,115 : INFO : PROGRESS: at sentence #780000, processed 10793581 words, keeping 73107 word types\n",
      "2020-01-22 21:06:33,149 : INFO : PROGRESS: at sentence #790000, processed 10933711 words, keeping 73548 word types\n",
      "2020-01-22 21:06:33,162 : INFO : collected 73717 word types from a corpus of 10978770 raw words and 793093 sentences\n",
      "2020-01-22 21:06:33,163 : INFO : Loading a fresh vocabulary\n",
      "2020-01-22 21:06:33,216 : INFO : effective_min_count=40 retains 8557 unique words (11% of original 73717, drops 65160)\n",
      "2020-01-22 21:06:33,217 : INFO : effective_min_count=40 leaves 10670794 word corpus (97% of original 10978770, drops 307976)\n",
      "2020-01-22 21:06:33,244 : INFO : deleting the raw counts dictionary of 73717 items\n",
      "2020-01-22 21:06:33,250 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2020-01-22 21:06:33,251 : INFO : downsampling leaves estimated 7804072 word corpus (73.1% of prior 10670794)\n",
      "2020-01-22 21:06:33,285 : INFO : estimated required memory for 8557 words and 300 dimensions: 24815300 bytes\n",
      "2020-01-22 21:06:33,285 : INFO : resetting layer weights\n",
      "2020-01-22 21:06:33,408 : INFO : training model with 4 workers on 8557 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-01-22 21:06:34,426 : INFO : EPOCH 1 - PROGRESS: at 10.94% examples, 846974 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:35,432 : INFO : EPOCH 1 - PROGRESS: at 22.33% examples, 864905 words/s, in_qsize 6, out_qsize 1\n",
      "2020-01-22 21:06:36,437 : INFO : EPOCH 1 - PROGRESS: at 33.79% examples, 873404 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:37,441 : INFO : EPOCH 1 - PROGRESS: at 45.10% examples, 874468 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:38,446 : INFO : EPOCH 1 - PROGRESS: at 56.39% examples, 874812 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:39,451 : INFO : EPOCH 1 - PROGRESS: at 67.21% examples, 869166 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:40,459 : INFO : EPOCH 1 - PROGRESS: at 78.68% examples, 871898 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:41,461 : INFO : EPOCH 1 - PROGRESS: at 89.67% examples, 869949 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:42,350 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:06:42,351 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:06:42,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:06:42,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:06:42,368 : INFO : EPOCH - 1 : training on 10978770 raw words (7804517 effective words) took 8.9s, 872133 effective words/s\n",
      "2020-01-22 21:06:43,383 : INFO : EPOCH 2 - PROGRESS: at 11.47% examples, 887561 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:44,388 : INFO : EPOCH 2 - PROGRESS: at 23.34% examples, 902815 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:45,390 : INFO : EPOCH 2 - PROGRESS: at 34.99% examples, 904249 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:46,392 : INFO : EPOCH 2 - PROGRESS: at 46.63% examples, 905229 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:47,396 : INFO : EPOCH 2 - PROGRESS: at 58.29% examples, 905274 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:48,398 : INFO : EPOCH 2 - PROGRESS: at 70.14% examples, 907721 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:49,403 : INFO : EPOCH 2 - PROGRESS: at 81.22% examples, 901321 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:50,414 : INFO : EPOCH 2 - PROGRESS: at 92.87% examples, 901040 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:51,015 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:06:51,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:06:51,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:06:51,035 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:06:51,036 : INFO : EPOCH - 2 : training on 10978770 raw words (7804030 effective words) took 8.7s, 900998 effective words/s\n",
      "2020-01-22 21:06:52,051 : INFO : EPOCH 3 - PROGRESS: at 11.39% examples, 882255 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:53,064 : INFO : EPOCH 3 - PROGRESS: at 22.88% examples, 882869 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:54,066 : INFO : EPOCH 3 - PROGRESS: at 34.71% examples, 895328 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:55,069 : INFO : EPOCH 3 - PROGRESS: at 46.27% examples, 896684 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:56,073 : INFO : EPOCH 3 - PROGRESS: at 57.74% examples, 895617 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:57,080 : INFO : EPOCH 3 - PROGRESS: at 69.31% examples, 895433 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:58,084 : INFO : EPOCH 3 - PROGRESS: at 80.76% examples, 894754 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:59,094 : INFO : EPOCH 3 - PROGRESS: at 92.42% examples, 895414 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:06:59,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:06:59,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:06:59,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:06:59,750 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:06:59,751 : INFO : EPOCH - 3 : training on 10978770 raw words (7802154 effective words) took 8.7s, 896166 effective words/s\n",
      "2020-01-22 21:07:00,765 : INFO : EPOCH 4 - PROGRESS: at 11.56% examples, 898411 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:01,774 : INFO : EPOCH 4 - PROGRESS: at 23.34% examples, 903566 words/s, in_qsize 8, out_qsize 0\n",
      "2020-01-22 21:07:02,780 : INFO : EPOCH 4 - PROGRESS: at 34.90% examples, 901395 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:03,791 : INFO : EPOCH 4 - PROGRESS: at 46.45% examples, 898912 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:04,802 : INFO : EPOCH 4 - PROGRESS: at 58.02% examples, 897699 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:05,805 : INFO : EPOCH 4 - PROGRESS: at 69.69% examples, 899061 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:06,813 : INFO : EPOCH 4 - PROGRESS: at 81.12% examples, 897402 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:07,819 : INFO : EPOCH 4 - PROGRESS: at 92.50% examples, 895379 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:08,455 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:07:08,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:07:08,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:07:08,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:07:08,474 : INFO : EPOCH - 4 : training on 10978770 raw words (7803835 effective words) took 8.7s, 895693 effective words/s\n",
      "2020-01-22 21:07:09,492 : INFO : EPOCH 5 - PROGRESS: at 11.47% examples, 887287 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:10,496 : INFO : EPOCH 5 - PROGRESS: at 23.34% examples, 903058 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:11,497 : INFO : EPOCH 5 - PROGRESS: at 34.53% examples, 893438 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:12,510 : INFO : EPOCH 5 - PROGRESS: at 46.09% examples, 892668 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:13,511 : INFO : EPOCH 5 - PROGRESS: at 57.56% examples, 892836 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:14,511 : INFO : EPOCH 5 - PROGRESS: at 68.95% examples, 891942 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:15,513 : INFO : EPOCH 5 - PROGRESS: at 80.39% examples, 892132 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:07:16,514 : INFO : EPOCH 5 - PROGRESS: at 91.77% examples, 891539 words/s, in_qsize 8, out_qsize 0\n",
      "2020-01-22 21:07:17,217 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:07:17,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:07:17,233 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:07:17,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:07:17,238 : INFO : EPOCH - 5 : training on 10978770 raw words (7803678 effective words) took 8.8s, 891430 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:07:17,238 : INFO : training on a 54893850 raw words (39018214 effective words) took 43.8s, 890227 effective words/s\n",
      "2020-01-22 21:07:17,239 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:07:17.267247Z",
     "start_time": "2020-01-23T05:07:17.257346Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # WV.Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = int(0.)\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:00.663090Z",
     "start_time": "2020-01-23T05:07:17.271668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 100000\n",
      "Review 2000 of 100000\n",
      "Review 3000 of 100000\n",
      "Review 4000 of 100000\n",
      "Review 5000 of 100000\n",
      "Review 6000 of 100000\n",
      "Review 7000 of 100000\n",
      "Review 8000 of 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 9000 of 100000\n",
      "Review 10000 of 100000\n",
      "Review 11000 of 100000\n",
      "Review 12000 of 100000\n",
      "Review 13000 of 100000\n",
      "Review 14000 of 100000\n",
      "Review 15000 of 100000\n",
      "Review 16000 of 100000\n",
      "Review 17000 of 100000\n",
      "Review 18000 of 100000\n",
      "Review 19000 of 100000\n",
      "Review 20000 of 100000\n",
      "Review 21000 of 100000\n",
      "Review 22000 of 100000\n",
      "Review 23000 of 100000\n",
      "Review 24000 of 100000\n",
      "Review 25000 of 100000\n",
      "Review 26000 of 100000\n",
      "Review 27000 of 100000\n",
      "Review 28000 of 100000\n",
      "Review 29000 of 100000\n",
      "Review 30000 of 100000\n",
      "Review 31000 of 100000\n",
      "Review 32000 of 100000\n",
      "Review 33000 of 100000\n",
      "Review 34000 of 100000\n",
      "Review 35000 of 100000\n",
      "Review 36000 of 100000\n",
      "Review 37000 of 100000\n",
      "Review 38000 of 100000\n",
      "Review 39000 of 100000\n",
      "Review 40000 of 100000\n",
      "Review 41000 of 100000\n",
      "Review 42000 of 100000\n",
      "Review 43000 of 100000\n",
      "Review 44000 of 100000\n",
      "Review 45000 of 100000\n",
      "Review 46000 of 100000\n",
      "Review 47000 of 100000\n",
      "Review 48000 of 100000\n",
      "Review 49000 of 100000\n",
      "Review 50000 of 100000\n",
      "Review 51000 of 100000\n",
      "Review 52000 of 100000\n",
      "Review 53000 of 100000\n",
      "Review 54000 of 100000\n",
      "Review 55000 of 100000\n",
      "Review 56000 of 100000\n",
      "Review 57000 of 100000\n",
      "Review 58000 of 100000\n",
      "Review 59000 of 100000\n",
      "Review 60000 of 100000\n",
      "Review 61000 of 100000\n",
      "Review 62000 of 100000\n",
      "Review 63000 of 100000\n",
      "Review 64000 of 100000\n",
      "Review 65000 of 100000\n",
      "Review 66000 of 100000\n",
      "Review 67000 of 100000\n",
      "Review 68000 of 100000\n",
      "Review 69000 of 100000\n",
      "Review 70000 of 100000\n",
      "Review 71000 of 100000\n",
      "Review 72000 of 100000\n",
      "Review 73000 of 100000\n",
      "Review 74000 of 100000\n",
      "Review 75000 of 100000\n",
      "Review 76000 of 100000\n",
      "Review 77000 of 100000\n",
      "Review 78000 of 100000\n",
      "Review 79000 of 100000\n",
      "Review 80000 of 100000\n",
      "Review 81000 of 100000\n",
      "Review 82000 of 100000\n",
      "Review 83000 of 100000\n",
      "Review 84000 of 100000\n",
      "Review 85000 of 100000\n",
      "Review 86000 of 100000\n",
      "Review 87000 of 100000\n",
      "Review 88000 of 100000\n",
      "Review 89000 of 100000\n",
      "Review 90000 of 100000\n",
      "Review 91000 of 100000\n",
      "Review 92000 of 100000\n",
      "Review 93000 of 100000\n",
      "Review 94000 of 100000\n",
      "Review 95000 of 100000\n",
      "Review 96000 of 100000\n",
      "Review 97000 of 100000\n",
      "Review 98000 of 100000\n",
      "Review 99000 of 100000\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_reviews = []\n",
    "for review in dfreviews[\"text\"]:\n",
    "    clean_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "reviewDataVecs = getAvgFeatureVecs( clean_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:01.223140Z",
     "start_time": "2020-01-23T05:09:00.667007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create df \n",
    "all_features_labels = ['w2v{}'.format(idx) for idx in range(reviewDataVecs.shape[1])]\n",
    "all_features_df = pd.DataFrame(data=reviewDataVecs, columns=all_features_labels)\n",
    "\n",
    "all_features_df['business_id'] = dfreviews['business_id']\n",
    "# Convert all but business_id to numerical\n",
    "# business_ids = all_features_df['business_id']\n",
    "# all_features_df = all_features_df.iloc[:,:-1].astype('float64')\n",
    "# all_features_df['business_id'] = business_ids\n",
    "# del business_ids\n",
    "\n",
    "# Group by business_id\n",
    "all_features_business = all_features_df.groupby(by='business_id').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Business Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:06.158537Z",
     "start_time": "2020-01-23T05:09:01.225487Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_business_df(): \n",
    "    filename = r'../../data/business.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfbusiness = load_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:06.342420Z",
     "start_time": "2020-01-23T05:09:06.160951Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add business categories to features df\n",
    "business_cols = ['business_id', 'categories']\n",
    "all_features_business = all_features_business.merge(dfbusiness[business_cols], how='left', on='business_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-23T05:11:50.914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def stringDFColToBinaryCols(df, series_name):\n",
    "    # Create list of all categories\n",
    "    all_cats = []\n",
    "    for string in df[series_name]:\n",
    "        string = str(string)\n",
    "        cats = string.strip().replace(' ', '').split(',')\n",
    "        for cat in cats:\n",
    "            if cat not in all_cats:\n",
    "                all_cats.append(cat)\n",
    "    # Make binary for each cat for each row\n",
    "    for cat in all_cats:\n",
    "        df[cat] = df[series_name].str.strip().str.replace(' ', '').str.contains(cat)\n",
    "        # This technique will have some problems. 'Golf' may appear in non-Golf categories (ie 'Disc Golf')\n",
    "        # Can be fixed with regular expressions: ',Golf,' OR 'BOF Golf,' OR ',Golf EOF'\n",
    "    \n",
    "    return df, all_cats\n",
    "\n",
    "# Business categories are encoded as a string. Convert that to binary columns for label prediction\n",
    "all_features_business, all_cats = stringDFColToBinaryCols(all_features_business, 'categories')\n",
    "\n",
    "# It will be helpful to have a Series object later\n",
    "all_cats_ser = pd.Series(data=all_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:38.123636Z",
     "start_time": "2020-01-23T05:09:36.274875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  13943\n",
      "After:   13922\n"
     ]
    }
   ],
   "source": [
    "# Clean\n",
    "\n",
    "# Remove rows with NaNs\n",
    "print('Before: ', len(all_features_business))\n",
    "all_features_business = all_features_business.dropna(axis=0)\n",
    "print('After:  ', len(all_features_business))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:39.175607Z",
     "start_time": "2020-01-23T05:09:38.126274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "\n",
    "# First, shuffle the dataframe \n",
    "# and reset the index. (Makes for easier handling of train/test splitting later)\n",
    "all_features_business = all_features_business.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create final y and x \n",
    "y_df = all_features_business[all_cats]\n",
    "x_cols = [ele for ele in all_features_business.columns if ele not in all_cats+['categories', 'business_id']]\n",
    "x_df = all_features_business[x_cols]\n",
    "\n",
    "# Numpy arrays for sklearn\n",
    "x = x_df.values\n",
    "y = y_df.values\n",
    "\n",
    "# Classifier wants 1/0, not T/F\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into Train/Test sets\n",
    "def splitSets(x, y, test_size=0.2):\n",
    "    test_size_absolute = np.int(test_size * len(x))\n",
    "    X_test, X_train = x[:test_size_absolute,:], x[test_size_absolute:,:]\n",
    "    y_test, y_train = y[:test_size_absolute,:], y[test_size_absolute:,:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = splitSets(x, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:09:39.305119Z",
     "start_time": "2020-01-23T05:09:39.177859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multilabel Classification\n",
    "# RandomForestClassifier supports multilabel classification\n",
    "\n",
    "# Most other classifiers will require use of \n",
    "    # sklearn.multioutput.MultiOutputClassifier to run a separate classifier model for each targe\n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:11:06.938785Z",
     "start_time": "2020-01-23T05:09:39.307238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:11:09.796963Z",
     "start_time": "2020-01-23T05:11:06.996574Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-23T05:11:53.949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter for recommendations. (Not presently listed) AND (predicted by algorithm)\n",
    "reccs_binary = (y_test == 0) & (y_predict == 1)\n",
    "\n",
    "# Create recommendations dataframe\n",
    "all_cats_true = []\n",
    "all_cats_recc = []\n",
    "for biz in range(len(y_test)):\n",
    "    cats_true = ', '.join(list(all_cats_ser[y_test[biz,:]==1]))\n",
    "    all_cats_true.append(cats_true)\n",
    "    \n",
    "    cats_recc = ', '.join(list(all_cats_ser[reccs_binary[biz,:]==True]))\n",
    "    all_cats_recc.append(cats_recc)\n",
    "reccs_df = pd.DataFrame(data=all_cats_true, columns=['Labeled'])\n",
    "reccs_df['Recommended'] = all_cats_recc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
