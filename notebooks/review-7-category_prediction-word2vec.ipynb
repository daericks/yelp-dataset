{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Acknowledgements\" data-toc-modified-id=\"Acknowledgements-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Acknowledgements</a></span></li><li><span><a href=\"#Prepare-data-and-model\" data-toc-modified-id=\"Prepare-data-and-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Prepare data and model</a></span></li><li><span><a href=\"#Make-feature-matrix-(word2vec,-votes,-stars)\" data-toc-modified-id=\"Make-feature-matrix-(word2vec,-votes,-stars)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Make feature matrix (word2vec, votes, stars)</a></span></li><li><span><a href=\"#Create-Label-y-(Business-categories)\" data-toc-modified-id=\"Create-Label-y-(Business-categories)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create Label y (Business categories)</a></span></li><li><span><a href=\"#Join-x,y-(feature-matrix,-category)-using-business_id\" data-toc-modified-id=\"Join-x,y-(feature-matrix,-category)-using-business_id-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Join x,y (feature matrix, category) using business_id</a></span></li><li><span><a href=\"#Category-Prediction\" data-toc-modified-id=\"Category-Prediction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Category Prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recall-(and-other-classification-metrics)\" data-toc-modified-id=\"Recall-(and-other-classification-metrics)-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Recall (and other classification metrics)</a></span></li><li><span><a href=\"#Top-RECOMMENDATIONS\" data-toc-modified-id=\"Top-RECOMMENDATIONS-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Top RECOMMENDATIONS</a></span></li></ul></li><li><span><a href=\"#Cluster-with-metadata-(useful,-cool,-funny,-stars)\" data-toc-modified-id=\"Cluster-with-metadata-(useful,-cool,-funny,-stars)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cluster with metadata (useful, cool, funny, stars)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-27T04:47:17.954Z"
    }
   },
   "source": [
    "# Acknowledgements\n",
    "Thanks to the tutorial: https://www.kaggle.com/c/word2vec-nlp-tutorial/overview/part-3-more-fun-with-word-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:16:37.590879Z",
     "start_time": "2020-01-22T09:16:31.610182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daviderickson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows=999\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:32:24.119122Z",
     "start_time": "2020-01-22T09:16:37.595590Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_reviews(size='small'): \n",
    "    if size == 'small':\n",
    "        filename = r'../../data/small-review.json'\n",
    "    elif size == 'intermediate':\n",
    "        filename = r'../../data/intermediate-review.json'\n",
    "    elif size == 'full':\n",
    "        filename = r'../../data/review.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfreviews = load_reviews(size='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:32:25.952714Z",
     "start_time": "2020-01-22T09:32:24.602763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0  2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0  2017-01-14 21:30:33      0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw     0  2016-11-09 20:09:03      0   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA     0  2018-01-09 20:56:38      0   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ     0  2018-01-30 23:07:38      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q    1.0   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q    5.0   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug    5.0   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig    5.0   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw    1.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2  I have to say that this office really has it t...       3   \n",
       "3  Went in for a lunch. Steak sandwich was delici...       0   \n",
       "4  Today was my second out of three sessions I ha...       7   \n",
       "\n",
       "                  user_id  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfreviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:32:25.970463Z",
     "start_time": "2020-01-22T09:32:25.961373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfreviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:32:26.086822Z",
     "start_time": "2020-01-22T09:32:25.973242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfreviews['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:44:36.168861Z",
     "start_time": "2020-01-22T09:32:26.089298Z"
    }
   },
   "outputs": [],
   "source": [
    "# For simplicity, drop anything that isn't a letter\n",
    "# Numbers and symbols may have interesting meaning and could be explore later\n",
    "\n",
    "def lettersOnly(string):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \", string) \n",
    "\n",
    "dfreviews['text'] = dfreviews['text'].apply(lettersOnly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:44:36.621965Z",
     "start_time": "2020-01-22T09:44:36.266956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total bill for this horrible service  Over   Gs  These crooks actually had the nerve to charge us     for   pills  I checked online the pills can be had for    cents EACH  Avoid Hospital ERs at all costs '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfreviews['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T09:44:37.457743Z",
     "start_time": "2020-01-22T09:44:36.651874Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(string, remove_stopwords=False):\n",
    "    string = re.sub(\"[^a-zA-Z]\", \" \", string) # keep only letters. more complex model possible later\n",
    "    words =  string.lower().split() # make everything lowercase. split into words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english')) # create a fast lookup for stopwords\n",
    "        words = [w for w in words if not w in stops] # remove stopwords\n",
    "    return( words) # return a list of words\n",
    "    \n",
    "# dfreviews['text'] = dfreviews['text'].apply(review_to_words) # apply to reviews in dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec expects single sentences, each one as a list of words\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences\")\n",
    "for review in dfreviews[\"text\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.759Z"
    }
   },
   "outputs": [],
   "source": [
    "model.most_similar('pizza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.772Z"
    }
   },
   "outputs": [],
   "source": [
    "model.most_similar('service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.784Z"
    }
   },
   "outputs": [],
   "source": [
    "model.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.795Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # WV.Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = int(0.)\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.812Z"
    }
   },
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_reviews = []\n",
    "for review in dfreviews[\"text\"]:\n",
    "    clean_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "reviewDataVecs = getAvgFeatureVecs( clean_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make feature matrix (word2vec, votes, stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.824Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewDataVecs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add non-text data back to feature matrix\n",
    "review_features = ['cool', 'funny', 'useful', 'stars' , 'business_id']\n",
    "all_features_labels = ['w2v{}'.format(idx) for idx in range(reviewDataVecs.shape[1])] + review_features\n",
    "all_features = np.append(reviewDataVecs, dfreviews[review_features].to_numpy(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create df \n",
    "all_features_df = pd.DataFrame(data=all_features, columns=all_features_labels)\n",
    "\n",
    "# Convert all but business_id to numerical\n",
    "business_ids = all_features_df['business_id']\n",
    "all_features_df = all_features_df.iloc[:,:-1].astype('float64')\n",
    "all_features_df['business_id'] = business_ids\n",
    "del business_ids\n",
    "\n",
    "# Group by business_id\n",
    "all_features_business = all_features_df.groupby(by='business_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.859Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.877Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Label y (Business categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.889Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_business_df(): \n",
    "    filename = r'../../data/business.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfbusiness = load_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.903Z"
    }
   },
   "outputs": [],
   "source": [
    "dfbusiness.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join x,y (feature matrix, category) using business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.913Z"
    }
   },
   "outputs": [],
   "source": [
    "dfbusiness.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.924Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dfbusiness['stars'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add business details to features df\n",
    "keep_cols = ['business_id', 'categories', 'review_count']\n",
    "all_features_business = all_features_business.merge(dfbusiness[keep_cols], how='left', on='business_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.947Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.956Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business['categories'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.972Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.982Z"
    }
   },
   "outputs": [],
   "source": [
    "def stringDFColToBinaryCols(df, series_name):\n",
    "    # Create list of all categories\n",
    "    all_cats = []\n",
    "    for string in df[series_name]:\n",
    "        string = str(string)\n",
    "        cats = string.strip().replace(' ', '').split(',')\n",
    "        for cat in cats:\n",
    "            if cat not in all_cats:\n",
    "                all_cats.append(cat)\n",
    "    # Make binary for each cat for each row\n",
    "    for cat in all_cats:\n",
    "        df[cat] = df[series_name].str.strip().str.replace(' ', '').str.contains(cat)\n",
    "        # This technique will have some problems. 'Golf' may appear in non-Golf categories (ie 'Disc Golf')\n",
    "        # Can be fixed with regular expressions: ',Golf,' OR 'BOF Golf,' OR ',Golf EOF'\n",
    "    \n",
    "    return df, all_cats\n",
    "        \n",
    "all_features_business, all_cats = stringDFColToBinaryCols(all_features_business, 'categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:31.993Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.003Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    len(all_features_business[all_features_business['Golf']==True]), \n",
    "    len(all_features_business[all_features_business['DiscGolf']==True]), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.013Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all_features_business[all_features_business['DiscGolf']==True]['categories'].values)\n",
    "print('Should not have a True value for Golf, but does. Problem to deal with in the future.')\n",
    "print(all_features_business[all_features_business['DiscGolf']==True]['Golf'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.046Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean\n",
    "\n",
    "# Remove rows with NaNs\n",
    "print('Before: ', len(all_features_business))\n",
    "all_features_business = all_features_business.dropna(axis=0)\n",
    "print('After:  ', len(all_features_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.064Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, shuffle the dataframe \n",
    "# and reset the index. (Makes for easier handling of train/test later)\n",
    "all_features_business = all_features_business.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create final y and x \n",
    "y_df = all_features_business[all_cats]\n",
    "x_cols = [ele for ele in all_features_business.columns if ele not in all_cats+['categories', 'business_id']]\n",
    "# May also want to remove from x_cols: 'cool', 'funny', 'useful', 'stars', 'categories', 'review_count' \n",
    "# May also want to drop rows that do not contain more than a threshold number of reviews (20?, 100?)\n",
    "x_df = all_features_business[x_cols]\n",
    "\n",
    "# Numpy arrays\n",
    "x = x_df.values\n",
    "y = y_df.values\n",
    "\n",
    "# Classifier wants 1/0, not T/F\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into Train/Test sets\n",
    "def splitSets(x, y, test_size=0.2):\n",
    "    test_size_absolute = np.int(test_size * len(x))\n",
    "    X_test, X_train = x[:test_size_absolute,:], x[test_size_absolute:,:]\n",
    "    y_test, y_train = y[:test_size_absolute,:], y[test_size_absolute:,:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = splitSets(x, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.076Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multilabel Classification\n",
    "# RandomForestClassifier supports multilabel classification\n",
    "\n",
    "# Most other classifiers will require use of \n",
    "    # sklearn.multioutput.MultiOutputClassifier to run a separate classifier model for each targe\n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.091Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.107Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall (and other classification metrics)\n",
    "\n",
    "In our case we want a Recall = TPR (True Positive Rate) close to 1 since we want to Recall ALL correct categories. \n",
    "\n",
    "The only requirement we have for Precision is that it be less than 1. This is because we want some FPs (False Positives) since these are what WE ARE RECOMMENDING!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_predict = rfc.predict(X_test)\n",
    "print(classification_report(y_test, y_predict, target_names=all_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.131Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score \n",
    "\n",
    "recall_all_cats = recall_score(y_test, y_predict, average=None)\n",
    "recall_all_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top RECOMMENDATIONS\n",
    "\n",
    "Look at the top NONMATCHING RESULTS, which are the top recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.138Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.152Z"
    }
   },
   "outputs": [],
   "source": [
    "print( len(y_proba), ' L')\n",
    "print( len(y_proba[0]), ' W')\n",
    "print( len(y_proba[0][0]), \" D (0: False prob'y, 1: True prob'y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.161Z"
    }
   },
   "outputs": [],
   "source": [
    "y_proba[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.171Z"
    }
   },
   "outputs": [],
   "source": [
    "reccs_binary = (y_test == 0) & (y_predict == 1)\n",
    "reccs_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.180Z"
    }
   },
   "outputs": [],
   "source": [
    "all_cats_ser = pd.Series(data=all_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.189Z"
    }
   },
   "outputs": [],
   "source": [
    "all_cats_true = []\n",
    "all_cats_recc = []\n",
    "for biz in range(len(y_test)):\n",
    "    cats_true = ', '.join(list(all_cats_ser[y_test[biz,:]==1]))\n",
    "    all_cats_true.append(cats_true)\n",
    "    \n",
    "    cats_recc = ', '.join(list(all_cats_ser[reccs_binary[biz,:]==True]))\n",
    "    all_cats_recc.append(cats_recc)\n",
    "\n",
    "reccs_df = pd.DataFrame(data=all_cats_true, columns=['Labeled'])\n",
    "reccs_df['Recommended'] = all_cats_recc\n",
    "reccs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.203Z"
    }
   },
   "outputs": [],
   "source": [
    "list(all_features_business.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.213Z"
    }
   },
   "outputs": [],
   "source": [
    "reccs_df['categories'] = all_features_business['categories'].iloc[:len(reccs_df)]\n",
    "reccs_df['business_id'] = all_features_business['business_id'].iloc[:len(reccs_df)]\n",
    "reccs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.221Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is where I need to pick up. I need to match the dataframes \n",
    "# so that I can match reviews etc and judge how well the recommender is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.230Z"
    }
   },
   "outputs": [],
   "source": [
    "list(all_features_business['categories'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.240Z"
    }
   },
   "outputs": [],
   "source": [
    "len(reccs_df[reccs_df['Recommended']!=''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.256Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reccs_df[reccs_df['Recommended']!=''].sort_values(by='Recommended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.264Z"
    }
   },
   "outputs": [],
   "source": [
    "dfreviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.275Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',2000)\n",
    "dfreviews[dfreviews['business_id']=='KN0gPRzDvA6uVYims2KA0w']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Given X_test row, find identical row in all_features_business and use that to find 'business_id'\n",
    "all_features_business[x_cols].values == X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.294Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-22T09:16:32.304Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features_business[x_cols].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
