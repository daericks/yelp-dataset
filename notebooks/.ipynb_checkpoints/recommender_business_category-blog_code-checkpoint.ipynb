{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Recommender-system-for-business-categories-of-Yelp-businesses.-Uses-reviews\" data-toc-modified-id=\"Recommender-system-for-business-categories-of-Yelp-businesses.-Uses-reviews-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Recommender system for business categories of Yelp businesses. Uses reviews</a></span></li><li><span><a href=\"#ETL-(Extract,-Transform,-Load)\" data-toc-modified-id=\"ETL-(Extract,-Transform,-Load)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ETL (Extract, Transform, Load)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Review-data\" data-toc-modified-id=\"Review-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Review data</a></span></li><li><span><a href=\"#Merge-with-Business-Categories\" data-toc-modified-id=\"Merge-with-Business-Categories-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Merge with Business Categories</a></span></li></ul></li><li><span><a href=\"#Recommender-System\" data-toc-modified-id=\"Recommender-System-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Recommender System</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Generate-recommendations\" data-toc-modified-id=\"Generate-recommendations-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generate recommendations</a></span></li><li><span><a href=\"#Link-to-reviews-to-validate-quality-of-recommendations\" data-toc-modified-id=\"Link-to-reviews-to-validate-quality-of-recommendations-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Link to reviews to validate quality of recommendations</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:27:47.959842Z",
     "start_time": "2020-01-23T04:27:47.954128Z"
    }
   },
   "source": [
    "# Recommender system for business categories of Yelp businesses. Uses reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:20:56.000439Z",
     "start_time": "2020-01-23T05:20:50.621412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daviderickson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:29:11.535609Z",
     "start_time": "2020-01-23T04:29:11.532284Z"
    }
   },
   "source": [
    "# ETL (Extract, Transform, Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T04:32:53.965254Z",
     "start_time": "2020-01-23T04:32:53.958871Z"
    }
   },
   "source": [
    "## Review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:20:57.134305Z",
     "start_time": "2020-01-23T05:20:56.004146Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_reviews(size='small'): \n",
    "    if size == 'small':\n",
    "        filename = r'../../data/small-review.json'\n",
    "    elif size == 'intermediate':\n",
    "        filename = r'../../data/intermediate-review.json'\n",
    "    elif size == 'full':\n",
    "        filename = r'../../data/review.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfreviews = load_reviews(size='intermediate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:20:57.157377Z",
     "start_time": "2020-01-23T05:20:57.138317Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(string, remove_stopwords=False):\n",
    "    string = re.sub(\"[^a-zA-Z]\", \" \", string) # keep only letters. more complex model possible later\n",
    "    words =  string.lower().split() # make everything lowercase. split into words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english')) # create a fast lookup for stopwords\n",
    "        words = [w for w in words if not w in stops] # remove stopwords\n",
    "    return( words) # return a list of words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:20:57.197738Z",
     "start_time": "2020-01-23T05:20:57.165084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec expects single sentences, each one as a list of words\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:21:24.381393Z",
     "start_time": "2020-01-23T05:20:57.200275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences\")\n",
    "for review in dfreviews[\"text\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:22:12.183943Z",
     "start_time": "2020-01-23T05:21:24.383953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:21:25,179 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2020-01-22 21:21:25,192 : INFO : collecting all words and their counts\n",
      "2020-01-22 21:21:25,194 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-01-22 21:21:25,237 : INFO : PROGRESS: at sentence #10000, processed 140966 words, keeping 9537 word types\n",
      "2020-01-22 21:21:25,271 : INFO : PROGRESS: at sentence #20000, processed 279509 words, keeping 13297 word types\n",
      "2020-01-22 21:21:25,301 : INFO : PROGRESS: at sentence #30000, processed 416170 words, keeping 16108 word types\n",
      "2020-01-22 21:21:25,334 : INFO : PROGRESS: at sentence #40000, processed 552466 words, keeping 18464 word types\n",
      "2020-01-22 21:21:25,363 : INFO : PROGRESS: at sentence #50000, processed 690423 words, keeping 20660 word types\n",
      "2020-01-22 21:21:25,393 : INFO : PROGRESS: at sentence #60000, processed 829572 words, keeping 22414 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:21:25,425 : INFO : PROGRESS: at sentence #70000, processed 967451 words, keeping 24105 word types\n",
      "2020-01-22 21:21:25,460 : INFO : PROGRESS: at sentence #80000, processed 1106355 words, keeping 25709 word types\n",
      "2020-01-22 21:21:25,493 : INFO : PROGRESS: at sentence #90000, processed 1245199 words, keeping 27118 word types\n",
      "2020-01-22 21:21:25,528 : INFO : PROGRESS: at sentence #100000, processed 1385155 words, keeping 28435 word types\n",
      "2020-01-22 21:21:25,559 : INFO : PROGRESS: at sentence #110000, processed 1522186 words, keeping 29854 word types\n",
      "2020-01-22 21:21:25,588 : INFO : PROGRESS: at sentence #120000, processed 1658125 words, keeping 31115 word types\n",
      "2020-01-22 21:21:25,622 : INFO : PROGRESS: at sentence #130000, processed 1797345 words, keeping 32404 word types\n",
      "2020-01-22 21:21:25,650 : INFO : PROGRESS: at sentence #140000, processed 1935475 words, keeping 33568 word types\n",
      "2020-01-22 21:21:25,683 : INFO : PROGRESS: at sentence #150000, processed 2074816 words, keeping 34612 word types\n",
      "2020-01-22 21:21:25,714 : INFO : PROGRESS: at sentence #160000, processed 2211922 words, keeping 35735 word types\n",
      "2020-01-22 21:21:25,744 : INFO : PROGRESS: at sentence #170000, processed 2347735 words, keeping 36668 word types\n",
      "2020-01-22 21:21:25,774 : INFO : PROGRESS: at sentence #180000, processed 2488067 words, keeping 37576 word types\n",
      "2020-01-22 21:21:25,804 : INFO : PROGRESS: at sentence #190000, processed 2625228 words, keeping 38448 word types\n",
      "2020-01-22 21:21:25,837 : INFO : PROGRESS: at sentence #200000, processed 2760045 words, keeping 39490 word types\n",
      "2020-01-22 21:21:25,867 : INFO : PROGRESS: at sentence #210000, processed 2898041 words, keeping 40365 word types\n",
      "2020-01-22 21:21:25,900 : INFO : PROGRESS: at sentence #220000, processed 3034056 words, keeping 41262 word types\n",
      "2020-01-22 21:21:25,942 : INFO : PROGRESS: at sentence #230000, processed 3173822 words, keeping 42201 word types\n",
      "2020-01-22 21:21:25,971 : INFO : PROGRESS: at sentence #240000, processed 3313085 words, keeping 43150 word types\n",
      "2020-01-22 21:21:26,010 : INFO : PROGRESS: at sentence #250000, processed 3455109 words, keeping 43971 word types\n",
      "2020-01-22 21:21:26,040 : INFO : PROGRESS: at sentence #260000, processed 3594317 words, keeping 44784 word types\n",
      "2020-01-22 21:21:26,073 : INFO : PROGRESS: at sentence #270000, processed 3734590 words, keeping 45550 word types\n",
      "2020-01-22 21:21:26,110 : INFO : PROGRESS: at sentence #280000, processed 3870748 words, keeping 46312 word types\n",
      "2020-01-22 21:21:26,136 : INFO : PROGRESS: at sentence #290000, processed 4006164 words, keeping 47097 word types\n",
      "2020-01-22 21:21:26,167 : INFO : PROGRESS: at sentence #300000, processed 4143319 words, keeping 47781 word types\n",
      "2020-01-22 21:21:26,212 : INFO : PROGRESS: at sentence #310000, processed 4283740 words, keeping 48478 word types\n",
      "2020-01-22 21:21:26,246 : INFO : PROGRESS: at sentence #320000, processed 4422585 words, keeping 49105 word types\n",
      "2020-01-22 21:21:26,280 : INFO : PROGRESS: at sentence #330000, processed 4560689 words, keeping 49851 word types\n",
      "2020-01-22 21:21:26,306 : INFO : PROGRESS: at sentence #340000, processed 4699298 words, keeping 50451 word types\n",
      "2020-01-22 21:21:26,336 : INFO : PROGRESS: at sentence #350000, processed 4839144 words, keeping 51110 word types\n",
      "2020-01-22 21:21:26,373 : INFO : PROGRESS: at sentence #360000, processed 4977867 words, keeping 51749 word types\n",
      "2020-01-22 21:21:26,399 : INFO : PROGRESS: at sentence #370000, processed 5117768 words, keeping 52413 word types\n",
      "2020-01-22 21:21:26,443 : INFO : PROGRESS: at sentence #380000, processed 5253185 words, keeping 53011 word types\n",
      "2020-01-22 21:21:26,469 : INFO : PROGRESS: at sentence #390000, processed 5391056 words, keeping 53645 word types\n",
      "2020-01-22 21:21:26,500 : INFO : PROGRESS: at sentence #400000, processed 5526783 words, keeping 54160 word types\n",
      "2020-01-22 21:21:26,535 : INFO : PROGRESS: at sentence #410000, processed 5665316 words, keeping 54708 word types\n",
      "2020-01-22 21:21:26,560 : INFO : PROGRESS: at sentence #420000, processed 5802570 words, keeping 55265 word types\n",
      "2020-01-22 21:21:26,592 : INFO : PROGRESS: at sentence #430000, processed 5943274 words, keeping 55836 word types\n",
      "2020-01-22 21:21:26,621 : INFO : PROGRESS: at sentence #440000, processed 6082899 words, keeping 56453 word types\n",
      "2020-01-22 21:21:26,660 : INFO : PROGRESS: at sentence #450000, processed 6222326 words, keeping 57059 word types\n",
      "2020-01-22 21:21:26,687 : INFO : PROGRESS: at sentence #460000, processed 6361761 words, keeping 57570 word types\n",
      "2020-01-22 21:21:26,717 : INFO : PROGRESS: at sentence #470000, processed 6501789 words, keeping 58120 word types\n",
      "2020-01-22 21:21:26,751 : INFO : PROGRESS: at sentence #480000, processed 6641871 words, keeping 58597 word types\n",
      "2020-01-22 21:21:26,785 : INFO : PROGRESS: at sentence #490000, processed 6778331 words, keeping 59152 word types\n",
      "2020-01-22 21:21:26,817 : INFO : PROGRESS: at sentence #500000, processed 6917652 words, keeping 59660 word types\n",
      "2020-01-22 21:21:26,848 : INFO : PROGRESS: at sentence #510000, processed 7054305 words, keeping 60216 word types\n",
      "2020-01-22 21:21:26,881 : INFO : PROGRESS: at sentence #520000, processed 7192561 words, keeping 60946 word types\n",
      "2020-01-22 21:21:26,918 : INFO : PROGRESS: at sentence #530000, processed 7331639 words, keeping 61435 word types\n",
      "2020-01-22 21:21:26,949 : INFO : PROGRESS: at sentence #540000, processed 7466412 words, keeping 61967 word types\n",
      "2020-01-22 21:21:26,982 : INFO : PROGRESS: at sentence #550000, processed 7606024 words, keeping 62444 word types\n",
      "2020-01-22 21:21:27,014 : INFO : PROGRESS: at sentence #560000, processed 7743467 words, keeping 62975 word types\n",
      "2020-01-22 21:21:27,046 : INFO : PROGRESS: at sentence #570000, processed 7886000 words, keeping 63441 word types\n",
      "2020-01-22 21:21:27,078 : INFO : PROGRESS: at sentence #580000, processed 8024498 words, keeping 63903 word types\n",
      "2020-01-22 21:21:27,111 : INFO : PROGRESS: at sentence #590000, processed 8163620 words, keeping 64465 word types\n",
      "2020-01-22 21:21:27,142 : INFO : PROGRESS: at sentence #600000, processed 8301154 words, keeping 64958 word types\n",
      "2020-01-22 21:21:27,175 : INFO : PROGRESS: at sentence #610000, processed 8439914 words, keeping 65389 word types\n",
      "2020-01-22 21:21:27,219 : INFO : PROGRESS: at sentence #620000, processed 8576668 words, keeping 65856 word types\n",
      "2020-01-22 21:21:27,248 : INFO : PROGRESS: at sentence #630000, processed 8716026 words, keeping 66276 word types\n",
      "2020-01-22 21:21:27,280 : INFO : PROGRESS: at sentence #640000, processed 8854192 words, keeping 66797 word types\n",
      "2020-01-22 21:21:27,313 : INFO : PROGRESS: at sentence #650000, processed 8993077 words, keeping 67312 word types\n",
      "2020-01-22 21:21:27,346 : INFO : PROGRESS: at sentence #660000, processed 9129112 words, keeping 67809 word types\n",
      "2020-01-22 21:21:27,379 : INFO : PROGRESS: at sentence #670000, processed 9268587 words, keeping 68228 word types\n",
      "2020-01-22 21:21:27,413 : INFO : PROGRESS: at sentence #680000, processed 9406880 words, keeping 68668 word types\n",
      "2020-01-22 21:21:27,450 : INFO : PROGRESS: at sentence #690000, processed 9546298 words, keeping 69107 word types\n",
      "2020-01-22 21:21:27,477 : INFO : PROGRESS: at sentence #700000, processed 9685619 words, keeping 69538 word types\n",
      "2020-01-22 21:21:27,509 : INFO : PROGRESS: at sentence #710000, processed 9824418 words, keeping 70055 word types\n",
      "2020-01-22 21:21:27,541 : INFO : PROGRESS: at sentence #720000, processed 9962900 words, keeping 70456 word types\n",
      "2020-01-22 21:21:27,572 : INFO : PROGRESS: at sentence #730000, processed 10098717 words, keeping 70840 word types\n",
      "2020-01-22 21:21:27,604 : INFO : PROGRESS: at sentence #740000, processed 10237042 words, keeping 71317 word types\n",
      "2020-01-22 21:21:27,640 : INFO : PROGRESS: at sentence #750000, processed 10375581 words, keeping 71843 word types\n",
      "2020-01-22 21:21:27,673 : INFO : PROGRESS: at sentence #760000, processed 10515679 words, keeping 72299 word types\n",
      "2020-01-22 21:21:27,704 : INFO : PROGRESS: at sentence #770000, processed 10654391 words, keeping 72720 word types\n",
      "2020-01-22 21:21:27,732 : INFO : PROGRESS: at sentence #780000, processed 10793581 words, keeping 73107 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:21:27,764 : INFO : PROGRESS: at sentence #790000, processed 10933711 words, keeping 73548 word types\n",
      "2020-01-22 21:21:27,774 : INFO : collected 73717 word types from a corpus of 10978770 raw words and 793093 sentences\n",
      "2020-01-22 21:21:27,774 : INFO : Loading a fresh vocabulary\n",
      "2020-01-22 21:21:27,815 : INFO : effective_min_count=40 retains 8557 unique words (11% of original 73717, drops 65160)\n",
      "2020-01-22 21:21:27,816 : INFO : effective_min_count=40 leaves 10670794 word corpus (97% of original 10978770, drops 307976)\n",
      "2020-01-22 21:21:27,845 : INFO : deleting the raw counts dictionary of 73717 items\n",
      "2020-01-22 21:21:27,850 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2020-01-22 21:21:27,852 : INFO : downsampling leaves estimated 7804072 word corpus (73.1% of prior 10670794)\n",
      "2020-01-22 21:21:27,879 : INFO : estimated required memory for 8557 words and 300 dimensions: 24815300 bytes\n",
      "2020-01-22 21:21:27,880 : INFO : resetting layer weights\n",
      "2020-01-22 21:21:28,002 : INFO : training model with 4 workers on 8557 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-01-22 21:21:29,011 : INFO : EPOCH 1 - PROGRESS: at 9.57% examples, 744761 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:30,017 : INFO : EPOCH 1 - PROGRESS: at 20.96% examples, 813592 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:31,018 : INFO : EPOCH 1 - PROGRESS: at 32.43% examples, 840160 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:32,025 : INFO : EPOCH 1 - PROGRESS: at 43.74% examples, 848954 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:33,030 : INFO : EPOCH 1 - PROGRESS: at 55.13% examples, 855894 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:34,037 : INFO : EPOCH 1 - PROGRESS: at 66.38% examples, 859051 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:35,040 : INFO : EPOCH 1 - PROGRESS: at 77.85% examples, 863778 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:36,045 : INFO : EPOCH 1 - PROGRESS: at 89.12% examples, 865347 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:37,033 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:21:37,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:21:37,049 : INFO : EPOCH 1 - PROGRESS: at 99.91% examples, 862514 words/s, in_qsize 1, out_qsize 1\n",
      "2020-01-22 21:21:37,050 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:21:37,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:21:37,053 : INFO : EPOCH - 1 : training on 10978770 raw words (7804074 effective words) took 9.0s, 862957 effective words/s\n",
      "2020-01-22 21:21:38,071 : INFO : EPOCH 2 - PROGRESS: at 11.47% examples, 889520 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:39,077 : INFO : EPOCH 2 - PROGRESS: at 23.43% examples, 906340 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:40,085 : INFO : EPOCH 2 - PROGRESS: at 35.45% examples, 914400 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:41,096 : INFO : EPOCH 2 - PROGRESS: at 47.29% examples, 914232 words/s, in_qsize 8, out_qsize 0\n",
      "2020-01-22 21:21:42,096 : INFO : EPOCH 2 - PROGRESS: at 59.19% examples, 917538 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:43,101 : INFO : EPOCH 2 - PROGRESS: at 70.69% examples, 912809 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:44,107 : INFO : EPOCH 2 - PROGRESS: at 82.22% examples, 910591 words/s, in_qsize 6, out_qsize 1\n",
      "2020-01-22 21:21:45,118 : INFO : EPOCH 2 - PROGRESS: at 93.78% examples, 908129 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:45,631 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:21:45,644 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:21:45,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:21:45,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:21:45,652 : INFO : EPOCH - 2 : training on 10978770 raw words (7803851 effective words) took 8.6s, 908716 effective words/s\n",
      "2020-01-22 21:21:46,662 : INFO : EPOCH 3 - PROGRESS: at 11.29% examples, 880004 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:47,662 : INFO : EPOCH 3 - PROGRESS: at 22.88% examples, 890435 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:48,668 : INFO : EPOCH 3 - PROGRESS: at 34.43% examples, 892648 words/s, in_qsize 6, out_qsize 0\n",
      "2020-01-22 21:21:49,680 : INFO : EPOCH 3 - PROGRESS: at 46.09% examples, 894248 words/s, in_qsize 6, out_qsize 1\n",
      "2020-01-22 21:21:50,688 : INFO : EPOCH 3 - PROGRESS: at 58.02% examples, 899931 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:51,692 : INFO : EPOCH 3 - PROGRESS: at 69.60% examples, 899598 words/s, in_qsize 6, out_qsize 1\n",
      "2020-01-22 21:21:52,698 : INFO : EPOCH 3 - PROGRESS: at 81.12% examples, 899174 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:53,700 : INFO : EPOCH 3 - PROGRESS: at 92.42% examples, 896549 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:54,338 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:21:54,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:21:54,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:21:54,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:21:54,360 : INFO : EPOCH - 3 : training on 10978770 raw words (7803552 effective words) took 8.7s, 896925 effective words/s\n",
      "2020-01-22 21:21:55,372 : INFO : EPOCH 4 - PROGRESS: at 11.39% examples, 886374 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:56,373 : INFO : EPOCH 4 - PROGRESS: at 22.97% examples, 893960 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:57,378 : INFO : EPOCH 4 - PROGRESS: at 34.15% examples, 885903 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:58,382 : INFO : EPOCH 4 - PROGRESS: at 45.63% examples, 887508 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:21:59,389 : INFO : EPOCH 4 - PROGRESS: at 57.29% examples, 890609 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:00,400 : INFO : EPOCH 4 - PROGRESS: at 68.86% examples, 890945 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:01,405 : INFO : EPOCH 4 - PROGRESS: at 80.67% examples, 894927 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:02,420 : INFO : EPOCH 4 - PROGRESS: at 92.05% examples, 892311 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:03,103 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:22:03,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:22:03,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:22:03,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:22:03,126 : INFO : EPOCH - 4 : training on 10978770 raw words (7805951 effective words) took 8.8s, 891577 effective words/s\n",
      "2020-01-22 21:22:04,145 : INFO : EPOCH 5 - PROGRESS: at 11.39% examples, 883274 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:05,162 : INFO : EPOCH 5 - PROGRESS: at 22.70% examples, 874295 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:06,164 : INFO : EPOCH 5 - PROGRESS: at 33.51% examples, 863831 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:07,165 : INFO : EPOCH 5 - PROGRESS: at 42.83% examples, 828998 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:08,179 : INFO : EPOCH 5 - PROGRESS: at 54.05% examples, 835615 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:09,192 : INFO : EPOCH 5 - PROGRESS: at 65.57% examples, 844732 words/s, in_qsize 8, out_qsize 0\n",
      "2020-01-22 21:22:10,198 : INFO : EPOCH 5 - PROGRESS: at 77.12% examples, 852099 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:11,206 : INFO : EPOCH 5 - PROGRESS: at 88.76% examples, 858348 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-22 21:22:12,147 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-22 21:22:12,153 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-22 21:22:12,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-22 21:22:12,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-22 21:22:12,166 : INFO : EPOCH - 5 : training on 10978770 raw words (7803621 effective words) took 9.0s, 864423 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-22 21:22:12,167 : INFO : training on a 54893850 raw words (39021049 effective words) took 44.2s, 883550 effective words/s\n",
      "2020-01-22 21:22:12,168 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:22:12.197899Z",
     "start_time": "2020-01-23T05:22:12.190389Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # WV.Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = int(0.)\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:23:47.571571Z",
     "start_time": "2020-01-23T05:22:12.200746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 100000\n",
      "Review 2000 of 100000\n",
      "Review 3000 of 100000\n",
      "Review 4000 of 100000\n",
      "Review 5000 of 100000\n",
      "Review 6000 of 100000\n",
      "Review 7000 of 100000\n",
      "Review 8000 of 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 9000 of 100000\n",
      "Review 10000 of 100000\n",
      "Review 11000 of 100000\n",
      "Review 12000 of 100000\n",
      "Review 13000 of 100000\n",
      "Review 14000 of 100000\n",
      "Review 15000 of 100000\n",
      "Review 16000 of 100000\n",
      "Review 17000 of 100000\n",
      "Review 18000 of 100000\n",
      "Review 19000 of 100000\n",
      "Review 20000 of 100000\n",
      "Review 21000 of 100000\n",
      "Review 22000 of 100000\n",
      "Review 23000 of 100000\n",
      "Review 24000 of 100000\n",
      "Review 25000 of 100000\n",
      "Review 26000 of 100000\n",
      "Review 27000 of 100000\n",
      "Review 28000 of 100000\n",
      "Review 29000 of 100000\n",
      "Review 30000 of 100000\n",
      "Review 31000 of 100000\n",
      "Review 32000 of 100000\n",
      "Review 33000 of 100000\n",
      "Review 34000 of 100000\n",
      "Review 35000 of 100000\n",
      "Review 36000 of 100000\n",
      "Review 37000 of 100000\n",
      "Review 38000 of 100000\n",
      "Review 39000 of 100000\n",
      "Review 40000 of 100000\n",
      "Review 41000 of 100000\n",
      "Review 42000 of 100000\n",
      "Review 43000 of 100000\n",
      "Review 44000 of 100000\n",
      "Review 45000 of 100000\n",
      "Review 46000 of 100000\n",
      "Review 47000 of 100000\n",
      "Review 48000 of 100000\n",
      "Review 49000 of 100000\n",
      "Review 50000 of 100000\n",
      "Review 51000 of 100000\n",
      "Review 52000 of 100000\n",
      "Review 53000 of 100000\n",
      "Review 54000 of 100000\n",
      "Review 55000 of 100000\n",
      "Review 56000 of 100000\n",
      "Review 57000 of 100000\n",
      "Review 58000 of 100000\n",
      "Review 59000 of 100000\n",
      "Review 60000 of 100000\n",
      "Review 61000 of 100000\n",
      "Review 62000 of 100000\n",
      "Review 63000 of 100000\n",
      "Review 64000 of 100000\n",
      "Review 65000 of 100000\n",
      "Review 66000 of 100000\n",
      "Review 67000 of 100000\n",
      "Review 68000 of 100000\n",
      "Review 69000 of 100000\n",
      "Review 70000 of 100000\n",
      "Review 71000 of 100000\n",
      "Review 72000 of 100000\n",
      "Review 73000 of 100000\n",
      "Review 74000 of 100000\n",
      "Review 75000 of 100000\n",
      "Review 76000 of 100000\n",
      "Review 77000 of 100000\n",
      "Review 78000 of 100000\n",
      "Review 79000 of 100000\n",
      "Review 80000 of 100000\n",
      "Review 81000 of 100000\n",
      "Review 82000 of 100000\n",
      "Review 83000 of 100000\n",
      "Review 84000 of 100000\n",
      "Review 85000 of 100000\n",
      "Review 86000 of 100000\n",
      "Review 87000 of 100000\n",
      "Review 88000 of 100000\n",
      "Review 89000 of 100000\n",
      "Review 90000 of 100000\n",
      "Review 91000 of 100000\n",
      "Review 92000 of 100000\n",
      "Review 93000 of 100000\n",
      "Review 94000 of 100000\n",
      "Review 95000 of 100000\n",
      "Review 96000 of 100000\n",
      "Review 97000 of 100000\n",
      "Review 98000 of 100000\n",
      "Review 99000 of 100000\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_reviews = []\n",
    "for review in dfreviews[\"text\"]:\n",
    "    clean_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "reviewDataVecs = getAvgFeatureVecs( clean_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:23:48.008644Z",
     "start_time": "2020-01-23T05:23:47.573704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create df \n",
    "all_features_labels = ['w2v{}'.format(idx) for idx in range(reviewDataVecs.shape[1])]\n",
    "all_features_df = pd.DataFrame(data=reviewDataVecs, columns=all_features_labels)\n",
    "\n",
    "all_features_df['business_id'] = dfreviews['business_id']\n",
    "# Convert all but business_id to numerical\n",
    "# business_ids = all_features_df['business_id']\n",
    "# all_features_df = all_features_df.iloc[:,:-1].astype('float64')\n",
    "# all_features_df['business_id'] = business_ids\n",
    "# del business_ids\n",
    "\n",
    "# Group by business_id\n",
    "all_features_business = all_features_df.groupby(by='business_id').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Business Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:23:52.700445Z",
     "start_time": "2020-01-23T05:23:48.012655Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_business_df(): \n",
    "    filename = r'../../data/business.json'\n",
    "    new_list = []\n",
    "    for line in open(filename):\n",
    "       new_list.append(json.loads(line))\n",
    "    return pd.DataFrame.from_records(new_list)\n",
    "\n",
    "dfbusiness = load_business_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:23:52.876546Z",
     "start_time": "2020-01-23T05:23:52.704597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add business categories to features df\n",
    "business_cols = ['business_id', 'categories']\n",
    "all_features_business = all_features_business.merge(dfbusiness[business_cols], how='left', on='business_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:24:20.003079Z",
     "start_time": "2020-01-23T05:23:52.879686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviderickson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def stringDFColToBinaryCols(df, series_name):\n",
    "    # Create list of all categories\n",
    "    all_cats = []\n",
    "    for string in df[series_name]:\n",
    "        string = str(string)\n",
    "        cats = string.strip().replace(' ', '').split(',')\n",
    "        for cat in cats:\n",
    "            if cat not in all_cats:\n",
    "                all_cats.append(cat)\n",
    "    # Make binary for each cat for each row\n",
    "    for cat in all_cats:\n",
    "        df[cat] = df[series_name].str.strip().str.replace(' ', '').str.contains(cat)\n",
    "        # This technique will have some problems. 'Golf' may appear in non-Golf categories (ie 'Disc Golf')\n",
    "        # Can be fixed with regular expressions: ',Golf,' OR 'BOF Golf,' OR ',Golf EOF'\n",
    "    \n",
    "    return df, all_cats\n",
    "\n",
    "# Business categories are encoded as a string. Convert that to binary columns for label prediction\n",
    "all_features_business, all_cats = stringDFColToBinaryCols(all_features_business, 'categories')\n",
    "\n",
    "# It will be helpful to have a Series object later\n",
    "all_cats_ser = pd.Series(data=all_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:24:21.760669Z",
     "start_time": "2020-01-23T05:24:20.004937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  13943\n",
      "After:   13922\n"
     ]
    }
   ],
   "source": [
    "# Clean\n",
    "\n",
    "# Remove rows with NaNs\n",
    "print('Before: ', len(all_features_business))\n",
    "all_features_business = all_features_business.dropna(axis=0)\n",
    "print('After:  ', len(all_features_business))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:24:22.801108Z",
     "start_time": "2020-01-23T05:24:21.763945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data for the model\n",
    "\n",
    "# First, shuffle the dataframe \n",
    "# and reset the index. (Makes for easier handling of train/test splitting later)\n",
    "all_features_business = all_features_business.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create final y and x \n",
    "y_df = all_features_business[all_cats]\n",
    "x_cols = [ele for ele in all_features_business.columns if ele not in all_cats+['categories', 'business_id']]\n",
    "x_df = all_features_business[x_cols]\n",
    "\n",
    "# Numpy arrays for sklearn\n",
    "x = x_df.values\n",
    "y = y_df.values\n",
    "\n",
    "# Classifier wants 1/0, not T/F\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into Train/Test sets\n",
    "def splitSets(x, y, test_size=0.2):\n",
    "    test_size_absolute = np.int(test_size * len(x))\n",
    "    X_test, X_train = x[:test_size_absolute,:], x[test_size_absolute:,:]\n",
    "    y_test, y_train = y[:test_size_absolute,:], y[test_size_absolute:,:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = splitSets(x, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:24:22.866105Z",
     "start_time": "2020-01-23T05:24:22.803366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multilabel Classification\n",
    "# RandomForestClassifier supports multilabel classification\n",
    "\n",
    "# Most other classifiers will require use of \n",
    "    # sklearn.multioutput.MultiOutputClassifier to run a separate classifier model for each targe\n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:45.878761Z",
     "start_time": "2020-01-23T05:24:22.868608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:48.415706Z",
     "start_time": "2020-01-23T05:25:45.885009Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:50.034872Z",
     "start_time": "2020-01-23T05:25:48.417766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter for recommendations. (Not presently listed) AND (predicted by algorithm)\n",
    "reccs_binary = (y_test == 0) & (y_predict == 1)\n",
    "\n",
    "# Create recommendations dataframe\n",
    "all_cats_true = []\n",
    "all_cats_recc = []\n",
    "for biz in range(len(y_test)):\n",
    "    cats_true = ', '.join(list(all_cats_ser[y_test[biz,:]==1]))\n",
    "    all_cats_true.append(cats_true)\n",
    "    \n",
    "    cats_recc = ', '.join(list(all_cats_ser[reccs_binary[biz,:]==True]))\n",
    "    all_cats_recc.append(cats_recc)\n",
    "reccs_df = pd.DataFrame(data=all_cats_true, columns=['Labeled Categories'])\n",
    "reccs_df['Recommended'] = all_cats_recc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:50.103266Z",
     "start_time": "2020-01-23T05:25:50.036820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labeled Categories</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Arts&amp;Entertainment, Stadiums&amp;Arenas</td>\n",
       "      <td>ActiveLife, Parks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>RealEstate, HomeServices, PropertyManagement, ...</td>\n",
       "      <td>Apartments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Automotive, AutoGlassServices, Wheel&amp;RimRepair...</td>\n",
       "      <td>AutoRepair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Automotive, CarStereoInstallation</td>\n",
       "      <td>AutoRepair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>Automotive, CarDealers</td>\n",
       "      <td>AutoRepair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>Automotive, BodyShops, Towing</td>\n",
       "      <td>AutoRepair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>LocalServices, HomeServices, WaterPurification...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>LocalServices, Shopping, ITServices&amp;ComputerRe...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>LocalServices, HomeServices, HomeCleaning, Car...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>LocalServices, Shopping, ActiveLife, SportingG...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>LocalServices, Couriers&amp;DeliveryServices</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>LocalServices, Shopping, ActiveLife, SportingG...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>Hotels, Hotels&amp;Travel, CarRental</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>Restaurants, Food, Donuts, Sandwiches, Bagels</td>\n",
       "      <td>Bakeries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Food, Desserts</td>\n",
       "      <td>Bakeries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>Restaurants, Tex-Mex, Mexican</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>Restaurants, African, SouthAfrican</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Restaurants, Sandwiches, Italian, Seafood, Ste...</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LocalServices, Gyms, Fitness&amp;Instruction, Acti...</td>\n",
       "      <td>Beauty&amp;Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Shopping, Health&amp;Medical, DiagnosticImaging, D...</td>\n",
       "      <td>Beauty&amp;Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Health&amp;Medical, MedicalCenters, DiagnosticServ...</td>\n",
       "      <td>Beauty&amp;Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Restaurants, Food, FastFood</td>\n",
       "      <td>Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Restaurants, Food, Bakeries, Sandwiches, Coffe...</td>\n",
       "      <td>Cafes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Automotive, AutoRepair, AutoGlassServices, Oil...</td>\n",
       "      <td>CarDealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>Restaurants, Food, SpecialtyFood, EthnicFood, ...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Restaurants, Thai</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Beauty&amp;Spas, Health&amp;Medical, Massage, MassageT...</td>\n",
       "      <td>DaySpas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Beauty&amp;Spas, MakeupArtists</td>\n",
       "      <td>DaySpas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>LocalServices, Sewing&amp;Alterations</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Pets, PetStores</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>Automotive, AutoParts&amp;Supplies</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>LocalServices, ShippingCenters, Notaries, Mail...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>HomeServices, BuildingSupplies</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>Beauty&amp;Spas, Tattoo</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Restaurants, Food, FastFood</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>Food, FarmersMarket, SpecialtyFood, Fruits&amp;Veg...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>ProfessionalServices, LocalServices, GraphicDe...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Automotive, AutoParts&amp;Supplies</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>Automotive, MotorcycleRepair, MotorcycleDealer...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>LocalServices, DryCleaning&amp;Laundry, DryCleanin...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>Automotive, AutoRepair, AutoDetailing, BodySho...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>Food, Grocery, OrganicStores</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>LocalServices, ShippingCenters, PrintingServic...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>Beauty&amp;Spas, Health&amp;Medical, SkinCare, HairSal...</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Arts&amp;Entertainment</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Food, SpecialtyFood, CandyStores</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Food, SpecialtyFood, Grocery, Fruits&amp;Veggies</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Food, Grocery</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>LocalServices, PrintingServices</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>Food, Grocery</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>LocalServices, Sewing&amp;Alterations</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Arts&amp;Entertainment, Cinema</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>LocalServices, ShoeRepair</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ProfessionalServices</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>LocalServices, SelfStorage</td>\n",
       "      <td>Shopping, HomeServices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Beauty&amp;Spas, DaySpas, Massage</td>\n",
       "      <td>SkinCare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Restaurants, Food, Donuts, Sandwiches, Coffee&amp;Tea</td>\n",
       "      <td>SpecialtyFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>EventPlanning&amp;Services, Hotels, Hotels&amp;Travel</td>\n",
       "      <td>Venues&amp;EventSpaces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Labeled Categories  \\\n",
       "1116                Arts&Entertainment, Stadiums&Arenas   \n",
       "1797  RealEstate, HomeServices, PropertyManagement, ...   \n",
       "613   Automotive, AutoGlassServices, Wheel&RimRepair...   \n",
       "737                   Automotive, CarStereoInstallation   \n",
       "2064                             Automotive, CarDealers   \n",
       "1249                      Automotive, BodyShops, Towing   \n",
       "2296  LocalServices, HomeServices, WaterPurification...   \n",
       "1807  LocalServices, Shopping, ITServices&ComputerRe...   \n",
       "2524  LocalServices, HomeServices, HomeCleaning, Car...   \n",
       "1704  LocalServices, Shopping, ActiveLife, SportingG...   \n",
       "1182           LocalServices, Couriers&DeliveryServices   \n",
       "1504  LocalServices, Shopping, ActiveLife, SportingG...   \n",
       "2735                   Hotels, Hotels&Travel, CarRental   \n",
       "2650      Restaurants, Food, Donuts, Sandwiches, Bagels   \n",
       "527                                      Food, Desserts   \n",
       "1917                               Restaurants, Italian   \n",
       "1899                                        Restaurants   \n",
       "1388                      Restaurants, Tex-Mex, Mexican   \n",
       "2347                 Restaurants, African, SouthAfrican   \n",
       "167   Restaurants, Sandwiches, Italian, Seafood, Ste...   \n",
       "611   LocalServices, Gyms, Fitness&Instruction, Acti...   \n",
       "526   Shopping, Health&Medical, DiagnosticImaging, D...   \n",
       "1669  Health&Medical, MedicalCenters, DiagnosticServ...   \n",
       "588                         Restaurants, Food, FastFood   \n",
       "421   Restaurants, Food, Bakeries, Sandwiches, Coffe...   \n",
       "320   Automotive, AutoRepair, AutoGlassServices, Oil...   \n",
       "2570  Restaurants, Food, SpecialtyFood, EthnicFood, ...   \n",
       "60                                    Restaurants, Thai   \n",
       "172   Beauty&Spas, Health&Medical, Massage, MassageT...   \n",
       "2671                         Beauty&Spas, MakeupArtists   \n",
       "...                                                 ...   \n",
       "169                   LocalServices, Sewing&Alterations   \n",
       "244                                     Pets, PetStores   \n",
       "2316                     Automotive, AutoParts&Supplies   \n",
       "1112  LocalServices, ShippingCenters, Notaries, Mail...   \n",
       "701                      HomeServices, BuildingSupplies   \n",
       "1370                                Beauty&Spas, Tattoo   \n",
       "607                         Restaurants, Food, FastFood   \n",
       "1915  Food, FarmersMarket, SpecialtyFood, Fruits&Veg...   \n",
       "600   ProfessionalServices, LocalServices, GraphicDe...   \n",
       "577                      Automotive, AutoParts&Supplies   \n",
       "2082  Automotive, MotorcycleRepair, MotorcycleDealer...   \n",
       "1887  LocalServices, DryCleaning&Laundry, DryCleanin...   \n",
       "2532  Automotive, AutoRepair, AutoDetailing, BodySho...   \n",
       "2179                       Food, Grocery, OrganicStores   \n",
       "2171  LocalServices, ShippingCenters, PrintingServic...   \n",
       "1739  Beauty&Spas, Health&Medical, SkinCare, HairSal...   \n",
       "1028                                 Arts&Entertainment   \n",
       "474                    Food, SpecialtyFood, CandyStores   \n",
       "1086       Food, SpecialtyFood, Grocery, Fruits&Veggies   \n",
       "1601                                      Food, Grocery   \n",
       "316                     LocalServices, PrintingServices   \n",
       "1088                                      Food, Grocery   \n",
       "279                   LocalServices, Sewing&Alterations   \n",
       "277                          Arts&Entertainment, Cinema   \n",
       "960                           LocalServices, ShoeRepair   \n",
       "2                                  ProfessionalServices   \n",
       "1896                         LocalServices, SelfStorage   \n",
       "1532                      Beauty&Spas, DaySpas, Massage   \n",
       "746   Restaurants, Food, Donuts, Sandwiches, Coffee&Tea   \n",
       "1262      EventPlanning&Services, Hotels, Hotels&Travel   \n",
       "\n",
       "                 Recommended  \n",
       "1116       ActiveLife, Parks  \n",
       "1797              Apartments  \n",
       "613               AutoRepair  \n",
       "737               AutoRepair  \n",
       "2064              AutoRepair  \n",
       "1249              AutoRepair  \n",
       "2296              Automotive  \n",
       "1807              Automotive  \n",
       "2524              Automotive  \n",
       "1704              Automotive  \n",
       "1182              Automotive  \n",
       "1504              Automotive  \n",
       "2735              Automotive  \n",
       "2650                Bakeries  \n",
       "527                 Bakeries  \n",
       "1917                    Bars  \n",
       "1899                    Bars  \n",
       "1388                    Bars  \n",
       "2347                    Bars  \n",
       "167                     Bars  \n",
       "611              Beauty&Spas  \n",
       "526              Beauty&Spas  \n",
       "1669             Beauty&Spas  \n",
       "588                  Burgers  \n",
       "421                    Cafes  \n",
       "320               CarDealers  \n",
       "2570                 Chinese  \n",
       "60                   Chinese  \n",
       "172                  DaySpas  \n",
       "2671                 DaySpas  \n",
       "...                      ...  \n",
       "169                 Shopping  \n",
       "244                 Shopping  \n",
       "2316                Shopping  \n",
       "1112                Shopping  \n",
       "701                 Shopping  \n",
       "1370                Shopping  \n",
       "607                 Shopping  \n",
       "1915                Shopping  \n",
       "600                 Shopping  \n",
       "577                 Shopping  \n",
       "2082                Shopping  \n",
       "1887                Shopping  \n",
       "2532                Shopping  \n",
       "2179                Shopping  \n",
       "2171                Shopping  \n",
       "1739                Shopping  \n",
       "1028                Shopping  \n",
       "474                 Shopping  \n",
       "1086                Shopping  \n",
       "1601                Shopping  \n",
       "316                 Shopping  \n",
       "1088                Shopping  \n",
       "279                 Shopping  \n",
       "277                 Shopping  \n",
       "960                 Shopping  \n",
       "2                   Shopping  \n",
       "1896  Shopping, HomeServices  \n",
       "1532                SkinCare  \n",
       "746            SpecialtyFood  \n",
       "1262      Venues&EventSpaces  \n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the recommendations\n",
    "reccs_df[reccs_df['Recommended']!=''].sort_values(by='Recommended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to reviews to validate quality of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:50.124021Z",
     "start_time": "2020-01-23T05:25:50.105375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include business_id so that we can use it as a key to find reviews for the business\n",
    "reccs_df['business_id'] = all_features_business['business_id'].iloc[:len(reccs_df)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T05:25:50.229941Z",
     "start_time": "2020-01-23T05:25:50.136452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6680                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This cute little place is really nearby my house and they have a lot of nice comfort food here.  I've only ever gone here for brunch and their portions are definitely big enough to share.  You can add little things (ie: side of peameal), etc.  The food is especially comforting when you have had a hangover the night before...\\n\\nThe decor is A-OK - very average - could probably use some updating.  The waitresses are all very sweet and polite.  Some are more accommodating than others.  One of them had let me upgrade (at an extra cost) from ham to peameal bacon whereas another told me that I had to order a side and I still had to deal with the piece of ham which I didn't end up eating.  \\n\\nGood food - not for everyday but if you want a nice cheap satisfying (high calorie) comforting breakfast.  It's good once in a while definitely and really much better than those main-stream brunch places.\n",
       "8688                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I met up with some friends for brunch and when we arrived here i was a bit surprised--amidst all the ethnic food in Scarborough, there is actually a very american family diner. The decor is perfectly dated and the food is classic. All day breakfast for about $10 gets you ample amount of eggs (3!) peameal bacon (3 giant slices) and home fries. I couldn't finish. The coffee is nonstop and the service is fantastic. One of my friends said she's been coming here with her family since she was little. How cute and cozy is that?\n",
       "13489                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Finally tried the Oreo pancakes. It would not be my first choice of breakfast type food (maybe for my son).  I will stick to classic breakfast and unlimited coffee! Yum\n",
       "23895                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Best breakfast in Toronto. The food at this place is outstanding. The portions are huge and everything is fresh. I love places like this where you get more than what you pay for.  LOVE THIS PLACE!\n",
       "36935                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Our favorite breakfast place. I'm all about supporting mom and pop's type businesses and this place is a gem. I love their early bird special. Best bacon out there; ask for extra crispy bacon and it's even better. Their prices are fair, the ambience is cozy and inviting, and the servers are so lovely. I love the servers there! They know my husband and I since we're regulars and they always make a point of saying hello to us. The place is usually busy, so expect to wait for a table, but it's not very long and well worth the wait. Oh, and they have really yummy pancakes and French Toast too!\n",
       "50071                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Decor: Odd. Outdated. Clean though if you strive to find a positive.\\n\\nStarter: Soup for the starter is the only reason this place got a two star rating. \\n\\nService: Waitress is cold. Akward. \\n\\nMain meal: Can i get a steak in my oil? The food on the plate tasted like oil.  \\n\\nOverall: Stay home and save your cash and tastebuds from a lofty blow.\n",
       "52387                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Better than Cora's. \\n\\nI was there for brunch and found that the food was delicious and the portions were very good. I had the Harvest breakfast and my girlfriend had the banquet burger. My French toast and sausages were better than ones I would have in other brunch places. My girlfriend usually eats pretty slowly, but she devoured the big burger within minutes, and she wasn't even really hungry. She said the burger could be better than Burger Priest...\\n\\nWe read some poor reviews about their service but I thought it was ok. We like the family ambiance of the place and the more casual service style. It wasn't too slow and the hostess was nice. I definitely would go back and I recommend people not to go for weekend brunches..only because I don't want to wait in line to get a seat...\n",
       "52679    Skip this place!!! Neither the food or the service worth going there.\\n\\nI'll keep it short and straight to the point.  I came for breakfast and ordered the following: Corned beef breakfast with tea, I asked the eggs to be over medium and to substitute home fries with tomatoes. \\n\\nAs soon as I got the plate I noticed that they forgot the tomatoes, so far, not a big deal.  I pointed out the mistake and within a minute or two I got my plate back with 4 slices of tomatoes.  The eggs were over easy and not over medium as I asked, the corned beef was salty, greasy and loaded with sodium, It's one of the rare times were I didn't finished the meat that was on my plate because it tasted so bad.\\n\\nAfter I finished the meal I asked for additional slices of bread, the waitress asked me if I want brown bread like before and I said yes.  the yes didn't seems to matter because I got white bread instead.. I didn't make a big deal out of it because I didn't want to stay there any longer.  \\n\\nWater refill for my tea was given only after asking specifically, they don't seems to walk around often to offer top-up.  At the end I was also charged extra for the tea despite the fact that their menu says \"free coffee and tea with every breakfast\", I asked the waitress why I was changed extra and she replied \"oh, this was an herbal tea it cost extra...\" It wasn't herbal tea it was Earl Grey tea, and last time I checked  Earl Grey  is not herbal but it didn't matter, they charge extra for that!!!\\n\\nAt the end of the day, this is the impression I got:  They can't get orders right, the food is oily and they charge extra for no reason.. \\n\\n I am not going there again!!!\n",
       "54736                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I've only been here for breakfast, but its a great family restaurant if you're looking for comfort food.  The ambiance is very classy, and so are their foods.  The prices are very reasonable, and the staff are accommodating.  I usually order their Early Bird, or NOT SO early bird breakfast.  Their pancakes are another yummy early bird thing to order.....nonetheless a family dive you can always go to where everybody knows your name...like CHEERS...\n",
       "80871                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Small place and service was alright. There was a line up at the door with a room full of staff but no one acknowledges you at first. After standing there for 10 mins, more people start showing up and finally starts to seat everyone.\\n\\nFirst time at this family restaurant for breakfast. I got the \"early bird\" which came with 3 eggs, sausage or bacon or ham and served with home fries, toast and a coffee. Food was good nothing over the top. Typical breakfast food. Our server was great, very nice and kept checking up on us. They kept up with the coffee refills so that was nice.\n",
       "98820                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Had the \"Early Bird Special\" .\\nEggs were perfect. Lots of bacon (5 pieces), that was also cooked perfectly. \\nPotatoes were ok, I'd say average. Tasty, but more on the mash / chopped side, which lends itself to be more like mashed. They weren't crispy, but, we're still tasty.\\nCoffee was hot and a bit above average.\\nMy wife commented that the water for her tea was hot, which if you're a tea drinker, you know is essential. Most places it is not hit enough.\\n\\nWill be back.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth',2000)\n",
    "def businessReviews(dfreviews=dfreviews, biz_id='KN0gPRzDvA6uVYims2KA0w'):\n",
    "    return dfreviews[dfreviews['business_id']=='KN0gPRzDvA6uVYims2KA0w']['text']\n",
    "\n",
    "businessReviews(dfreviews, biz_id='KN0gPRzDvA6uVYims2KA0w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
